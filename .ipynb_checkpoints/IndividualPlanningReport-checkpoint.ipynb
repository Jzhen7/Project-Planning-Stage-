{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "091b965f-8444-48bf-8a03-c13a9fa14f87",
   "metadata": {},
   "source": [
    "(1)\n",
    "\n",
    "The \"players\" dataset contains information regarding 196 unique players (rows) and seven seperate relevant observations (columns). \n",
    "\n",
    "- The first column is self-reported categorical data labeled experience, split into five categories indicating gaming profficiency starting from beginner, to amateur, to regular, to veteran, to pro.\n",
    "      - Potential issues regarding this data is that it is purely subjective.\n",
    "- The second column, subscribe, is if they are subscribed to a gaming newsletter in the form of Boolean.\n",
    "- The third column, hashedEmail, represents the participants email address.\n",
    "      - Not useful.\n",
    "- The fourth column, played_hours, is numeric data of total number of hours each participant spent playing in the MineCraft server.\n",
    "    - Most likely recorded through MineCraft Server logs\n",
    "- The fifth column are the participants' names,\n",
    "       - Not useful.\n",
    "- The sixth column is categorical data of the participant's gender\n",
    "       - Seems to have a strong imbalance with majority of male participants.\n",
    "- The final column contains each participants' age.\n",
    "      -Ranges from 17-26, with outliers of 57, 50, 9, and more.\n",
    "\n",
    "The \"sessions\" dataset contains information regarding every single individual playing session on the MineCraft Server. There are a total of 1535 playing sessions (rows) with 5 relevant observations (columns).\n",
    "\n",
    "- The first column is hashedEmail.\n",
    "      - Not useful.\n",
    "- The second column is start_time, represented in human-readable form, day/month/year hour:minute.\n",
    "    - Along with the end_time, most likely calculated from UNIX timestamps\n",
    "- The third column is end_time.\n",
    "- The forth column is original_start_time, recorded as a UNIX timestamp (milliseconds since 1 Jan 1970).\n",
    "    - Formatted in scientific notation, which may cause precision loss\n",
    "    - Along with original_end_time, most likely recorded through MineCraft Server logs\n",
    "- The fifth column is original_end_time\n",
    "\n",
    "(2)\n",
    "\n",
    "Broad Question: What player characteristics and behaviours are most predictive of subscribing to a game-related newsletter, and how do these features differ between various player types?\n",
    "\n",
    "Specific Question: Can a playerâ€™s experience level, average playtime, and demographic attributes (age, gender) predict whether they are subscribed (subscribe = TRUE)?\n",
    "\n",
    "\n",
    "The data I plan on using will all be in the players dataset. I plan on using the experience, played_hours, gender, and age as explanatory variables to predict response variable subscribe. I plan to first remove useless columns, such as name and hashedEmail using select. I will then convert catgorical variables such as exeprience and gender using as_factor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd1f9a-07b7-4915-9fcf-92cc39005518",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(repr)\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "options(repr.matrix.max.rows = 10)\n",
    "source(\"cleanup.R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659b0f8a-3e57-4a48-b93f-88fdb615b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "players <- read_csv(\"data/players.csv\")\n",
    "players_tidy <- players |> \n",
    "            rename(age = Age) |>\n",
    "            select(-name, -hashedEmail)\n",
    "mean_table <- players_tidy |>\n",
    "  summarise(mean_played_hours = mean(played_hours, na.rm = TRUE), mean_age = mean(age, na.rm = TRUE))\n",
    "mean_table\n",
    "\n",
    "players_experience <- ggplot(players_tidy, aes(x = experience, fill = subscribe)) +\n",
    "  geom_bar(position = \"fill\") +\n",
    "  scale_y_continuous(labels = scales::percent) +\n",
    "  labs(\n",
    "    title = \"Newsletter Subscription Rate by Experience Level\",\n",
    "    x = \"Experience Level\",\n",
    "    y = \"Percentage of Players\",\n",
    "    fill = \"Subscribed\")\n",
    "\n",
    "players_gender <- ggplot(players, aes(x = gender, fill = subscribe)) +\n",
    "  geom_bar(position = \"fill\") +\n",
    "  scale_y_continuous(labels = scales::percent) +\n",
    "  labs(\n",
    "    title = \"Newsletter Subscription Rate by Gender\",\n",
    "    x = \"Gender\",\n",
    "    y = \"Percentage of Players\",\n",
    "    fill = \"Subscribed\")\n",
    "\n",
    "players_gender\n",
    "players_experience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a899ba-08f6-4cbc-bd47-8c9fab109772",
   "metadata": {},
   "source": [
    "In the first graph, we are able to see how newsletter subscription rates vary across genders, but are limited by small sample sizes for some categories. Additionally, the data doesn't allow us to make any explicit conclusions yet, but does allow us to see how a majority of these groups are subscribed. The second plot shows us the relationship between experience level and subscription rates and allows us to observe that the proportions are quite similar, suggesting that experience might not be a strong predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11d1ccf-913b-4cbd-8934-d91d23768a30",
   "metadata": {},
   "source": [
    "(4)\n",
    "\n",
    "I propose to use Knn-classification since our response variable, subscribe, is categorical, not numerical. Additionally, Knn predicts the class of an observation by observing its nearest neighbors, therefore it is well-suited for datasets with mixed numeric (played_hours, age) and categorical (experience, gender) predictors. \n",
    "\n",
    "Knn has three crucial assumptions: Similar observations are closer together and numerical values are scaled appropriately, each row represents an independent observation, and each class has sufficient representation. However, a limitation of Knn is if a class doesn't have sufficient representation, it can offset the model. Additionally, it is very dependent on the K value, which we will tune the number of neighbors (k) using cross-validation on the training set. For each k value, we will evaluate model performance using metrics such as Accuracy or Precision and recall. I also plan on splitting the data into 80% training and 20% testing. \n",
    "\n",
    "(5)\n",
    "https://github.com/Jzhen7/Project-Planning-Stage- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
